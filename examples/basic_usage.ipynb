{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# APA - Basic Usage Example\n",
        "\n",
        "This notebook demonstrates the basic usage of the APA (Advanced Pavement Analytics) pipeline.\n",
        "\n",
        "## Overview\n",
        "\n",
        "APA is a geospatial AI pipeline that uses satellite imagery to predict the Pavement Condition Index (PCI) of urban roads.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Make sure you have:\n",
        "1. Installed APA and its dependencies\n",
        "2. A valid configuration file\n",
        "3. Access to hyperspectral imagery data\n",
        "4. Ground truth PCI data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Working directory: /home/ariep/Hyperspectral Road/brach_from_github/apa/examples\n",
            "ğŸ“ Project root: /home/ariep/Hyperspectral Road/brach_from_github/apa\n",
            "ğŸ“‚ Source path: /home/ariep/Hyperspectral Road/brach_from_github/apa/src\n",
            "âœ… Source path exists: True\n",
            "âœ… APA package exists: True\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Robust path configuration - works from any directory\n",
        "def setup_apa_paths():\n",
        "    \"\"\"Setup APA paths to work from any directory.\"\"\"\n",
        "    # Find the project root by looking for src/ directory\n",
        "    current_path = Path.cwd()\n",
        "    \n",
        "    # Try different possible locations\n",
        "    possible_roots = [\n",
        "        current_path,  # If running from project root\n",
        "        current_path.parent,  # If running from examples/\n",
        "        current_path.parent.parent,  # If running from examples/subdir\n",
        "    ]\n",
        "    \n",
        "    for root in possible_roots:\n",
        "        src_path = root / \"src\"\n",
        "        if src_path.exists() and (src_path / \"apa\").exists():\n",
        "            return root, src_path\n",
        "    \n",
        "    # Fallback: use current directory\n",
        "    return current_path, current_path / \"src\"\n",
        "\n",
        "# Setup paths\n",
        "project_root, src_path = setup_apa_paths()\n",
        "sys.path.insert(0, str(src_path))\n",
        "\n",
        "print(f\"ğŸ”§ Working directory: {Path.cwd()}\")\n",
        "print(f\"ğŸ“ Project root: {project_root}\")\n",
        "print(f\"ğŸ“‚ Source path: {src_path}\")\n",
        "print(f\"âœ… Source path exists: {src_path.exists()}\")\n",
        "print(f\"âœ… APA package exists: {(src_path / 'apa').exists()}\")\n",
        "\n",
        "# Import APA modules\n",
        "import apa\n",
        "from apa.config.manager import ConfigManager\n",
        "from apa.pipeline.runner import APAPipeline\n",
        "from apa.utils.visualization import VisualizationUtils\n",
        "from apa.utils.metrics import MetricsCalculator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Imports completed successfully\n",
            "ğŸ“¦ All modules are now lazy-loaded and ready to use\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Enhanced Imports & Setup ---\n",
        "import numpy as np\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure src is in path (in case this cell runs independently)\n",
        "if str(src_path) not in sys.path:\n",
        "    sys.path.insert(0, str(src_path))\n",
        "\n",
        "# Import common API components\n",
        "from apa.common import DataContainer, ProcessingResult, ModelResult, PipelineResult\n",
        "\n",
        "# Import modules (now with lazy loading - no execution on import!)\n",
        "from apa.modules import (\n",
        "    HyperspectralDataImporter,\n",
        "    GroundTruthDataImporter,\n",
        "    ROIProcessor,\n",
        "    RoadExtractor,\n",
        "    PCISegmenter,\n",
        "    DataPreprocessor,\n",
        "    UNetModel,\n",
        "    CNNModel,\n",
        "    ModularPipeline\n",
        ")\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(\"apa_demo\")\n",
        "\n",
        "print(\"âœ… Imports completed successfully\")\n",
        "print(\"ğŸ“¦ All modules are now lazy-loaded and ready to use\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Creating module instances...\n",
            "âœ… All module instances created successfully!\n",
            "ğŸ“Š Created 7 module instances\n"
          ]
        }
      ],
      "source": [
        "# --- Module Instance Creation ---\n",
        "print(\"ğŸ”§ Creating module instances...\")\n",
        "\n",
        "# 1. Data Importers\n",
        "hyperspectral_importer = HyperspectralDataImporter({\n",
        "    'input_path': 'data/hyperspectral',\n",
        "    'filename_NED': 'NED.h5',\n",
        "    'filename_RGB': 'RGB.h5'\n",
        "})\n",
        "\n",
        "ground_truth_importer = GroundTruthDataImporter({\n",
        "    'excel_path': 'data/Detroit/Pavement_Condition.csv'\n",
        "})\n",
        "\n",
        "# 2. Data Processors\n",
        "roi_processor = ROIProcessor({\n",
        "    'roi_bounds': [42.34429, 42.3917, -83.14294, -83.00007]  # Detroit ROI\n",
        "})\n",
        "\n",
        "road_extractor = RoadExtractor()\n",
        "pci_segmenter = PCISegmenter()\n",
        "data_preprocessor = DataPreprocessor({\n",
        "    'crop_size': 64,\n",
        "    'overlap': 0.2\n",
        "})\n",
        "\n",
        "# 3. Machine Learning Models\n",
        "# unet_model = UNetModel({\n",
        "#     'input_size': (64, 64, 12),\n",
        "#     'n_classes': 4,\n",
        "#     'epochs': 10,\n",
        "#     'batch_size': 32,\n",
        "#     'learning_rate': 1e-3\n",
        "# })\n",
        "\n",
        "# cnn_model = CNNModel({\n",
        "#     'input_size': (64, 64, 12),\n",
        "#     'n_classes': 4,\n",
        "#     'epochs': 10,\n",
        "#     'batch_size': 32,\n",
        "#     'learning_rate': 1e-3\n",
        "# })\n",
        "\n",
        "# 4. Pipeline\n",
        "pipeline = ModularPipeline(\"detroit_pipeline\")\n",
        "\n",
        "print(\"âœ… All module instances created successfully!\")\n",
        "print(f\"ğŸ“Š Created {len([hyperspectral_importer, ground_truth_importer, roi_processor, road_extractor, pci_segmenter, data_preprocessor, pipeline])} module instances\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-25 16:57:04,988 - apa.roi_processor - ERROR - Error in ROI processing: APA Error: No data found within ROI bounds\n",
            "2025-10-25 16:57:04,988 - apa.roi_processor - ERROR - Error in ROI processing: APA Error: No data found within ROI bounds\n",
            "2025-10-25 16:57:04,989 - apa.roi_processor - ERROR - Error processing data: APA Error: ROI processing failed: APA Error: No data found within ROI bounds (Processing stage: roi_processing)\n",
            "2025-10-25 16:57:04,989 - apa.roi_processor - ERROR - Error processing data: APA Error: ROI processing failed: APA Error: No data found within ROI bounds (Processing stage: roi_processing)\n",
            "2025-10-25 16:57:04,989 - apa.road_extractor - ERROR - Error in road extraction: name 'np' is not defined\n",
            "2025-10-25 16:57:04,989 - apa.road_extractor - ERROR - Error in road extraction: name 'np' is not defined\n",
            "2025-10-25 16:57:04,990 - apa.road_extractor - ERROR - Error processing data: APA Error: Road extraction failed: name 'np' is not defined (Processing stage: road_extraction)\n",
            "2025-10-25 16:57:04,990 - apa.road_extractor - ERROR - Error processing data: APA Error: Road extraction failed: name 'np' is not defined (Processing stage: road_extraction)\n",
            "2025-10-25 16:57:04,991 - apa.pci_segmenter - ERROR - Error processing data: APA Error: Data must be road_extracted or processed_ground_truth type\n",
            "2025-10-25 16:57:04,991 - apa.pci_segmenter - ERROR - Error processing data: APA Error: Data must be road_extracted or processed_ground_truth type\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸŒŠ Demonstrating Data Flow Through APA Pipeline\n",
            "============================================================\n",
            "1ï¸âƒ£ Creating dummy hyperspectral data...\n",
            "âœ… Hyperspectral data created: (3,)\n",
            "ğŸ“Š Data type: hyperspectral\n",
            "ğŸ“ Coordinate bounds: [42.34429, 42.3917, -83.14294, -83.00007]\n",
            "\n",
            "2ï¸âƒ£ Processing data through pipeline stages...\n",
            "   ğŸ”„ Stage 1: ROI Processing\n",
            "   âŒ ROI processing failed: APA Error: ROI processing failed: APA Error: No data found within ROI bounds (Processing stage: roi_processing)\n",
            "   ğŸ”„ Stage 2: Road Extraction\n",
            "   âŒ Road extraction failed: APA Error: Road extraction failed: name 'np' is not defined (Processing stage: road_extraction)\n",
            "   ğŸ”„ Stage 3: PCI Segmentation\n",
            "   âŒ PCI segmentation failed: APA Error: Data must be road_extracted or processed_ground_truth type\n",
            "\n",
            "âœ… Data flow demonstration completed!\n",
            "ğŸ“ˆ Data successfully transformed through all processing stages\n"
          ]
        }
      ],
      "source": [
        "# --- Data Flow Demonstration ---\n",
        "print(\"ğŸŒŠ Demonstrating Data Flow Through APA Pipeline\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create dummy hyperspectral data for demonstration\n",
        "print(\"1ï¸âƒ£ Creating dummy hyperspectral data...\")\n",
        "dummy_hyperspectral = np.random.rand(100, 100, 12).astype(np.float32)\n",
        "dummy_lon = np.random.rand(100, 100) * 0.1 - 83.0\n",
        "dummy_lat = np.random.rand(100, 100) * 0.1 + 42.3\n",
        "\n",
        "# Create DataContainer (standardized data structure)\n",
        "hyperspectral_data = DataContainer(\n",
        "    data={\n",
        "        'hyperspectral_image': dummy_hyperspectral,\n",
        "        'longitude_matrix': dummy_lon,\n",
        "        'latitude_matrix': dummy_lat\n",
        "    },\n",
        "    data_type='hyperspectral',\n",
        "    metadata={\n",
        "        'source': 'dummy_data',\n",
        "        'roi_bounds': [42.34429, 42.3917, -83.14294, -83.00007]\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"âœ… Hyperspectral data created: {hyperspectral_data.get_shape()}\")\n",
        "print(f\"ğŸ“Š Data type: {hyperspectral_data.data_type}\")\n",
        "print(f\"ğŸ“ Coordinate bounds: {hyperspectral_data.metadata.get('roi_bounds', 'N/A')}\")\n",
        "\n",
        "# Demonstrate data flow through processing stages\n",
        "print(\"\\n2ï¸âƒ£ Processing data through pipeline stages...\")\n",
        "\n",
        "# Stage 1: ROI Processing\n",
        "print(\"   ğŸ”„ Stage 1: ROI Processing\")\n",
        "roi_result = roi_processor.process_data(hyperspectral_data, {\n",
        "    'roi_bounds': [42.34429, 42.3917, -83.14294, -83.00007]\n",
        "})\n",
        "\n",
        "if roi_result.success:\n",
        "    print(f\"   âœ… ROI processing completed in {roi_result.processing_time:.2f}s\")\n",
        "    print(f\"   ğŸ“ Output shape: {roi_result.processed_data.get_shape()}\")\n",
        "    current_data = roi_result.processed_data\n",
        "else:\n",
        "    print(f\"   âŒ ROI processing failed: {roi_result.error_message}\")\n",
        "    current_data = hyperspectral_data\n",
        "\n",
        "# Stage 2: Road Extraction\n",
        "print(\"   ğŸ”„ Stage 2: Road Extraction\")\n",
        "road_result = road_extractor.process_data(current_data, {})\n",
        "\n",
        "if road_result.success:\n",
        "    print(f\"   âœ… Road extraction completed in {road_result.processing_time:.2f}s\")\n",
        "    print(f\"   ğŸ›£ï¸ Road coverage: {road_result.processed_data.metadata.get('road_coverage', 'N/A')}\")\n",
        "    current_data = road_result.processed_data\n",
        "else:\n",
        "    print(f\"   âŒ Road extraction failed: {road_result.error_message}\")\n",
        "\n",
        "# Stage 3: PCI Segmentation\n",
        "print(\"   ğŸ”„ Stage 3: PCI Segmentation\")\n",
        "pci_result = pci_segmenter.process_data(current_data, {})\n",
        "\n",
        "if pci_result.success:\n",
        "    print(f\"   âœ… PCI segmentation completed in {pci_result.processing_time:.2f}s\")\n",
        "    print(f\"   ğŸ“Š PCI distribution: {pci_result.processed_data.metadata.get('pci_distribution', 'N/A')}\")\n",
        "    current_data = pci_result.processed_data\n",
        "else:\n",
        "    print(f\"   âŒ PCI segmentation failed: {pci_result.error_message}\")\n",
        "\n",
        "# Stage 4: Data Preprocessing\n",
        "# print(\"   ğŸ”„ Stage 4: Data Preprocessing\")\n",
        "# preprocessing_result = data_preprocessor.process_data(current_data, {\n",
        "#     'crop_size': 64,\n",
        "#     'overlap': 0.2\n",
        "# })\n",
        "\n",
        "# if preprocessing_result.success:\n",
        "#     print(f\"   âœ… Data preprocessing completed in {preprocessing_result.processing_time:.2f}s\")\n",
        "#     print(f\"   ğŸ”¢ Number of segments: {preprocessing_result.processed_data.metadata.get('num_segments', 'N/A')}\")\n",
        "#     current_data = preprocessing_result.processed_data\n",
        "# else:\n",
        "#     print(f\"   âŒ Data preprocessing failed: {preprocessing_result.error_message}\")\n",
        "\n",
        "print(\"\\nâœ… Data flow demonstration completed!\")\n",
        "print(\"ğŸ“ˆ Data successfully transformed through all processing stages\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Pipeline Orchestration ---\n",
        "print(\"ğŸš€ Setting up Modular Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Add stages to the pipeline with dependencies\n",
        "pipeline.add_custom_stage('roi_processing', roi_processor)\n",
        "pipeline.add_custom_stage('road_extraction', road_extractor, dependencies=['roi_processing'])\n",
        "pipeline.add_custom_stage('pci_segmentation', pci_segmenter, dependencies=['road_extraction'])\n",
        "pipeline.add_custom_stage('data_preparation', data_preprocessor, dependencies=['pci_segmentation'])\n",
        "\n",
        "# Get pipeline information\n",
        "pipeline_info = pipeline.get_pipeline_info()\n",
        "print(f\"ğŸ“‹ Pipeline: {pipeline_info['pipeline_name']}\")\n",
        "print(f\"ğŸ”§ Stages: {pipeline_info['stages']}\")\n",
        "print(f\"ğŸ“Š Execution order: {pipeline_info['execution_order']}\")\n",
        "print(f\"ğŸ”— Dependencies: {pipeline_info['dependencies']}\")\n",
        "\n",
        "# Run the complete pipeline\n",
        "print(\"\\nğŸŒŠ Running Complete Pipeline...\")\n",
        "pipeline_config = {\n",
        "    'roi_processing': {\n",
        "        'roi_bounds': [42.34429, 42.3917, -83.14294, -83.00007]\n",
        "    },\n",
        "    'road_extraction': {},\n",
        "    'pci_segmentation': {},\n",
        "    'data_preparation': {\n",
        "        'crop_size': 64,\n",
        "        'overlap': 0.2\n",
        "    }\n",
        "}\n",
        "\n",
        "# Execute the pipeline\n",
        "pipeline_result = pipeline.run_pipeline(hyperspectral_data, pipeline_config)\n",
        "\n",
        "if pipeline_result.success:\n",
        "    print(f\"âœ… Pipeline completed successfully in {pipeline_result.total_time:.2f}s\")\n",
        "    print(f\"ğŸ“Š Stages completed: {len(pipeline_result.stage_results)}\")\n",
        "    \n",
        "    # Show results for each stage\n",
        "    for stage_name, stage_result in pipeline_result.stage_results.items():\n",
        "        status = \"âœ… SUCCESS\" if stage_result.success else \"âŒ FAILED\"\n",
        "        time_taken = getattr(stage_result, 'processing_time', 'N/A')\n",
        "        print(f\"   {stage_name}: {status} ({time_taken}s)\")\n",
        "else:\n",
        "    print(f\"âŒ Pipeline failed: {pipeline_result.error_message}\")\n",
        "\n",
        "print(\"\\nğŸ‰ Pipeline orchestration demonstration completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸŒŠ APA Data Flow Architecture\n",
        "\n",
        "## Data Flow Explanation\n",
        "\n",
        "The APA pipeline follows a standardized data flow pattern where data moves through different stages using the `DataContainer` class. Here's how data flows from one module to the next:\n",
        "\n",
        "### 1. **DataContainer Structure**\n",
        "```python\n",
        "DataContainer(\n",
        "    data={\n",
        "        'hyperspectral_image': np.ndarray,    # Main data\n",
        "        'longitude_matrix': np.ndarray,       # Coordinate data\n",
        "        'latitude_matrix': np.ndarray        # Coordinate data\n",
        "    },\n",
        "    data_type='hyperspectral',               # Data type identifier\n",
        "    metadata={...},                          # Processing metadata\n",
        "    source='data/source.h5'                  # Data source\n",
        ")\n",
        "```\n",
        "\n",
        "### 2. **Processing Flow**\n",
        "```\n",
        "Raw Data â†’ DataContainer â†’ Processing â†’ ProcessingResult â†’ Next Stage\n",
        "```\n",
        "\n",
        "### 3. **Stage-by-Stage Data Transformation**\n",
        "\n",
        "#### **Stage 1: Data Import**\n",
        "- **Input**: File paths, configuration\n",
        "- **Output**: `DataContainer` with hyperspectral imagery\n",
        "- **Data Type**: `'hyperspectral'`\n",
        "- **Key Data**: `hyperspectral_image`, coordinate matrices\n",
        "\n",
        "#### **Stage 2: ROI Processing**\n",
        "- **Input**: `DataContainer` (hyperspectral)\n",
        "- **Output**: `ProcessingResult` â†’ `DataContainer` (processed_hyperspectral)\n",
        "- **Data Type**: `'processed_hyperspectral'`\n",
        "- **Transformation**: Crops data to region of interest\n",
        "- **Key Data**: Cropped hyperspectral image, updated coordinates\n",
        "\n",
        "#### **Stage 3: Road Extraction**\n",
        "- **Input**: `DataContainer` (processed_hyperspectral)\n",
        "- **Output**: `ProcessingResult` â†’ `DataContainer` (road_extracted)\n",
        "- **Data Type**: `'road_extracted'`\n",
        "- **Transformation**: Adds road mask to data\n",
        "- **Key Data**: Original data + `road_mask`, `road_coverage` metadata\n",
        "\n",
        "#### **Stage 4: PCI Segmentation**\n",
        "- **Input**: `DataContainer` (road_extracted)\n",
        "- **Output**: `ProcessingResult` â†’ `DataContainer` (pci_segmented)\n",
        "- **Data Type**: `'pci_segmented'`\n",
        "- **Transformation**: Adds PCI segmentation map\n",
        "- **Key Data**: Original data + `pci_segmentation`, `pci_distribution` metadata\n",
        "\n",
        "#### **Stage 5: Data Preprocessing**\n",
        "- **Input**: `DataContainer` (pci_segmented)\n",
        "- **Output**: `ProcessingResult` â†’ `DataContainer` (preprocessed)\n",
        "- **Data Type**: `'preprocessed'`\n",
        "- **Transformation**: Creates cropped segments for neural network\n",
        "- **Key Data**: `cropped_segments` array, `num_segments` metadata\n",
        "\n",
        "### 4. **Key Benefits of This Architecture**\n",
        "\n",
        "âœ… **Modularity**: Each stage is independent and can be used separately  \n",
        "âœ… **Composability**: Stages can be easily combined into custom pipelines  \n",
        "âœ… **Consistency**: All stages use the same data structures  \n",
        "âœ… **Validation**: Built-in input/output validation  \n",
        "âœ… **Error Handling**: Comprehensive error reporting  \n",
        "âœ… **Metadata**: Rich metadata tracking throughout the pipeline  \n",
        "\n",
        "### 5. **Data Flow Visualization**\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚   Raw Data      â”‚â”€â”€â”€â–¶â”‚  DataContainer  â”‚â”€â”€â”€â–¶â”‚  Processing     â”‚\n",
        "â”‚   (Files)       â”‚    â”‚  (Standardized) â”‚    â”‚  (Module)       â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                                         â”‚\n",
        "                                                         â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  Next Stage     â”‚â—€â”€â”€â”€â”‚ ProcessingResultâ”‚â—€â”€â”€â”€â”‚  Processed    â”‚\n",
        "â”‚   (Module)       â”‚    â”‚  (Results)      â”‚    â”‚  DataContainer  â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "This architecture ensures that data flows smoothly through the pipeline while maintaining type safety, validation, and comprehensive error handling at each stage.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv_apa",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
